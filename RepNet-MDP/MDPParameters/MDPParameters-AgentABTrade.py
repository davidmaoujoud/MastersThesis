
class MDPParameters:

    def __init__(self, decay=0.7, learning_rate=1, delta_weight=0.8, update_function="difference_update", epsilon_convergence=0.1, steps=100, lookahead_depth=2, first_state=0, use_oracle=True):
        self.decay = decay
        self.learning_rate = learning_rate
        self.delta_weight = delta_weight
        self.update_function = update_function
        self.epsilon_convergence = epsilon_convergence
        self.steps = steps
        self.lookahead_depth = lookahead_depth
        self.first_state = first_state
        self.use_oracle = use_oracle


        self.directed_transition_models = [
            # Agent 1/G
            [
                [[[]]]  # Start in state 0
            ],

            # Agent 2/A
            [
                [[[]]]
            ]
        ]





    # :::::::::::::::::::::Tests, compare directed and undirected:::::::::::::::::::::::::::::::::::::






        # Actions: do_good, buy, consume, accept, refuse, nothing
        self.undirected_transition_models = [
            # Agent 1/G
            [ #    do_good              buy                 consume             accept                   refuse             nothing
                [[0.1,0.9,0,0,0],   [0.05,0.05,0,0.9,0],   [1/3,1/3,0,1/3,0],    [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],     [1,0,0,0,0]],
                [[0,1/2,1/2,0,0],     [0,0,1,0,0],         [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],       [0,1/2,1/2,0,0],       [0,1,0,0,0]    ],
                [[1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],    [1/3,0,1/3,0,1/3],     [1/3,0,1/3,0,1/3]  ],
                [[1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],    [1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],      [1/3,0,0,1/3,1/3] ],
                [[1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],          [1,0,0,0,0],         [1,0,0,0,0]        ]
            ],

            # Agent 2/A
            [ #    do_good              buy                 consume             accept                   refuse             nothing
                [[1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],    [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],     [1/3,1/3,0,1/3,0]],
                [[0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],      [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],       [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0]  ],
                [[1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [0,0,0,0,1],            [1,0,0,0,0],       [0,0,1,0,0]  ],
                [[1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],    [1/3,0,0,1/3,1/3],   [0,0,0,0,1],          [1,0,0,0,0],        [0,0,0,1,0] ],
                [[1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],          [1,0,0,0,0],         [1,0,0,0,0]        ]
            ]
        ]

        # wait_for_A
        self.directed_transition_models = [
            # Agent 1/G
            [
                [[[]]]  # Start in state 0
            ],

            # Agent 2/A
            [
                [[[]]]
            ]
        ]

        # Actions: do_good, buy, consume, accept, refuse, nothing
        # Impact(agent1, agent2, state, action_performed_by_agent2)
        self.impact_function = [
            [
                [[1,1,0,0,0,0,0], [0,1,0,0,0,0,0], [0,0,0,0,0,1,0], [0,0,0,0,0,1,0], [0,0,1,0,0,0,0]],
                [[0,0,0,0,0,0,0], [0,0,0,0,0,0,0], [0,0,0,1,-1,0,0], [0,0,0,1,-1,0,0],[0,0,0,0,0,0,0]]
            ],

            [
                [[1,-1,0,0,0,0,0], [0,1,0,0,0,0,0], [0,0,0,0,0,0,0], [0,0,0,0,0,0,0], [0,0,0,0,0,0,0]],
                [[0,0,0,0,0,1,0],  [0,0,0,0,0,1,0], [0,0,0,1,-1,0,0], [0,0,0,-1,1,0,0], [0,0,0,0,0,0,0]]
            ]
        ]

















        # Actions: do_good, buy, consume, accept, refuse, nothing
        self.undirected_transition_models = [
            # Agent 1/G
            [ #    do_good              buy                 consume             accept                   refuse             nothing
                [[0,1,0,0,0],         [0,0,0,1,0],         [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],   [1,0,0,0,0]       ],
                [[0,0.8,0.2,0,0],     [0,0,1,0,0],         [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],     [0,1,0,0,0]       ],
                [[1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3] ],
                [[1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3] ],
                [[1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0]       ]
            ],

            # Agent 2/A
            [ #    do_good              buy                 consume             accept                   refuse             nothing
                [[1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0]],
                [[0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0]  ],
                [[1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [0,0,0,0,1],         [1,0,0,0,0],         [0,0,1,0,0]      ],
                [[1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [0,0,0,0,1],         [1,0,0,0,0],         [0,0,0,1,0]      ],
                [[1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0]      ]
            ]
        ]

        self.subjective_transition_models = [
            # Agent 1/G
            [ #    do_good              buy                 consume             accept                   refuse             nothing
                [[0,1,0,0,0],         [0,0,0,1,0],         [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],     [1,0,0,0,0]       ],
                [[0,0.8,0.2,0,0],     [0,0,1,0,0],         [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],       [0,1,0,0,0]       ],
                [[1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],     [1/3,0,1/3,0,1/3] ],
                [[1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],     [1/3,0,0,1/3,1/3] ],
                [[1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],           [1,0,0,0,0]       ]
            ],

            # Agent 2/A
            [ #    do_good              buy                 consume             accept                   refuse             nothing
                [[1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],    [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0] ],
                [[0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],      [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0]   ],
                [[1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [0.15,0,0.15,0,0.7],  [0.7,0,0.15,0,0.15], [0,0,1,0,0]       ],
                [[1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [0.15,0,0,0.15,0.7],  [0.7,0,0,0.15,0.15], [0,0,0,1,0]       ],
                [[1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],          [1,0,0,0,0],         [1,0,0,0,0]       ]
            ]
        ]

        # wait_for_A
        self.directed_transition_models = [
            # Agent 1/G
            [
                [[[1,1,1,1,1],           [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0]]           ],  # Start in state 0
                [[[0,0,0,0,0],           [1,1,1,1,1], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0]]           ],  # Start in state 1
                [[[1/3,1/3,1/3,1/3,1/3], [0,0,0,0,0], [1/3,1/3,1/3,1/3,1/3], [0,0,0,0,0], [1/3,1/3,1/3,1/3,1/3]] ],  # Start in state 2
                [[[1/3,1/3,1/3,1/3,1/3], [0,0,0,0,0], [0,0,0,0,0], [1/3,1/3,1/3,1/3,1/3], [1/3,1/3,1/3,1/3,1/3]] ],  # Start in state 3
                [[[1,1,1,1,1],           [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0]]           ]   # Start in state 4
            ],

            # Agent 2/A
            [
                [[[0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0]]          ],  # Start in state 0
                [[[0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0]]          ],  # Start in state 1
                [[[0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0]]          ],  # Start in state 2
                [[[0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0]]          ],  # Start in state 3
                [[[0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0]]          ]   # Start in state 4
            ]
        ]

        # Actions: do_good, buy, consume, accept, refuse, nothing
        # Impact(agent1, agent2, state, action_performed_by_agent2)
        self.impact_function = [
            [
                [[0.5,0.4,0,0,0,0,0], [0.4,0.5,0,0,0,0,0], [0,0,0,0,0,0,0], [0,0,0,0,0,0,0], [0,0,1,0,0,0,0]],
                [[0,0,0,0,0,0,0],     [0,0,0,0,0,0,0],     [0,0,0,1,-1,0,0],   [0,0,0,1,-1,0,0],   [0,0,0,0,0,0,0]]
            ],

            [
                [[1,-1,0,0,0,0,0], [0,1,0,0,0,0,0], [0,0,0,0,0,0,0],  [0,0,0,0,0,0,0],  [0,0,0,0,0,0,0]],
                [[0,0,0,0,0,1,0],  [0,0,0,0,0,1,0], [0,0,0,1,-1,0,0], [0,0,0,-1,1,0,0], [0,0,0,0,0,1,0]]
            ]
        ]















        # Actions: do_good, buy, consume, accept, refuse, nothing
        self.undirected_transition_models = [
            # Agent 1/G
            [ #    do_good              buy                 consume             accept                   refuse             nothing
                [[0,1,0,0,0],         [0,0,0,1,0],         [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],   [1,0,0,0,0]       ],
                [[0,0.8,0.2,0,0],     [0,0,1,0,0],         [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],     [0,1,0,0,0]       ],
                [[1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3] ],
                [[1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3] ],
                [[1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0]       ]
            ],

            # Agent 2/A
            [ #    do_good              buy                 consume             accept                   refuse             nothing
                [[1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0]],
                [[0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0]  ],
                [[1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [0,0,0,0,1],         [1,0,0,0,0],         [0,0,1,0,0]      ],
                [[1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [0,0,0,0,1],         [1,0,0,0,0],         [0,0,0,1,0]      ],
                [[1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0]      ]
            ]
        ]

        self.subjective_transition_models = [
            # Agent 1/G
            [ #    do_good              buy                 consume             accept                   refuse             nothing
                [[0,1,0,0,0],         [0,0,0,1,0],         [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],     [1,0,0,0,0]       ],
                [[0,0.8,0.2,0,0],     [0,0,1,0,0],         [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],       [0,1,0,0,0]       ],
                [[1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],     [1/3,0,1/3,0,1/3] ],
                [[1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],     [1/3,0,0,1/3,1/3] ],
                [[1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],           [1,0,0,0,0]       ]
            ],

            # Agent 2/A
            [ #    do_good              buy                 consume             accept                   refuse             nothing
                [[1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0],    [1/3,1/3,0,1/3,0],   [1/3,1/3,0,1/3,0] ],
                [[0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0],      [0,1/2,1/2,0,0],     [0,1/2,1/2,0,0]   ],
                [[1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [1/3,0,1/3,0,1/3],   [0.15,0,0.15,0,0.7],  [0.7,0,0.15,0,0.15], [0,0,1,0,0]       ],
                [[1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [1/3,0,0,1/3,1/3],   [0.15,0,0,0.15,0.7],  [0.7,0,0,0.15,0.15], [0,0,0,1,0]       ],
                [[1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],         [1,0,0,0,0],          [1,0,0,0,0],         [1,0,0,0,0]       ]
            ]
        ]

        # wait_for_A
        self.directed_transition_models = [
            # Agent 1/G
            [
                [[[1,1,1,1,1],           [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0]]           ],  # Start in state 0
                [[[0,0,0,0,0],           [1,1,1,1,1], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0]]           ],  # Start in state 1
                [[[1,2/3,0,0,0], [0,0,0,0,0], [0,1/3,1/3,1/3,0], [0,0,0,0,0], [0,0,1/3,2/3,1]] ],  # Start in state 2 -> Agent A has a realistic view on when agent B might reject a trade offer
                #[[[1/3,1/3,1/3,1/3,1/3], [0,0,0,0,0], [1/3,1/3,1/3,1/3,1/3], [0,0,0,0,0], [1/3,1/3,1/3,1/3,1/3]] ],  # Start in state 2
                #[[[0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [1,1,1,1,1]] ],  # Start in state 2 -> Agent A thinks Agent B will accept the trade offer no matter its reputation (naive)
                [[[1/3,1/3,1/3,1/3,1/3], [0,0,0,0,0], [0,0,0,0,0], [1/3,1/3,1/3,1/3,1/3], [1/3,1/3,1/3,1/3,1/3]] ],  # Start in state 3
                [[[1,1,1,1,1],           [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0]]           ]   # Start in state 4
            ],

            # Agent 2/A
            [
                [[[0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0]]          ],  # Start in state 0
                [[[0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0]]          ],  # Start in state 1
                [[[0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0]]          ],  # Start in state 2
                [[[0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0]]          ],  # Start in state 3
                [[[0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0], [0,0,0,0,0]]          ]   # Start in state 4
            ]
        ]

        # Actions: do_good, buy, consume, accept, refuse, nothing
        # Impact(agent1, agent2, state, action_performed_by_agent2)
        self.impact_function = [
            [
                [[0.5,0.4,0,0,0,0,0], [0.5,0.9,0,0,0,0,0], [0,0,0,0,0,0,0], [0,0,0,0,0,0,0], [0,0,1,0,0,0,0]],
                [[0,0,0,0,0,0,0],     [0,0,0,0,0,0,0],     [0,0,0,1,-1,0,0],   [0,0,0,1,-1,0,0],   [0,0,0,0,0,0,0]]
            ],

            [
                [[1,-1,0,0,0,0,0], [0,1,0,0,0,0,0], [0,0,0,0,0,0,0],  [0,0,0,0,0,0,0],  [0,0,0,0,0,0,0]],
                [[0,0,0,0,0,1,0],  [0,0,0,0,0,1,0], [0,0,0,1,-1,0,0], [0,0,0,-1,1,0,0], [0,0,0,0,0,1,0]]
            ]
        ]

        self.restrictions = [
            [(2,6), (3,6)], # In states 2 and 3, agent A must pick a directed transition
            []
        ]
